{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31853f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the iris dataset as an example\n",
    "import numpy as np # for numpy\n",
    "# Now import a multiclassification model from a neural network for training multiclassification data\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Now import the libraries in sklearn that are used to evaluate the prediction metrics, such as confusion matrices\n",
    "#and classification reports\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris_data = load_iris()\n",
    "X = iris_data.data\n",
    "y = iris_data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    " X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6777e3d8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ']' (Temp/ipykernel_19236/3044027182.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\nada7\\AppData\\Local\\Temp/ipykernel_19236/3044027182.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    max(0, x)]\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ']'\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"\n",
    "# Main parameters.\n",
    "# hidden_layer_sizes: number of hidden layer cells (tuples), e.g. (100,100,100,50)\n",
    "# activation : activation function, {'identity', 'logistic', 'tanh', 'relu'}, default 'relu'; [f(x) = x, 1/(1+exp(-x)), tanh(x),\n",
    "#max(0, x)]\n",
    "# solver : solver, {'lbfgs', 'sgd', 'adam'}, default 'adam '; [newton method, stochastic gradient descent, adaptive\n",
    "#momemtum]\n",
    "# alpha : L2 regularization parameter, float, optional, default 0.0001\n",
    "# batch_size : batch size, optional, not applicable to 'lbfgs', default 'auto', in this case, batch_size=min(200,\n",
    "#n_samples)`\n",
    "# learning_rate : learning rate, {'constant', 'invscaling', 'adaptive'}, default 'constant', only for gradient descent sgd\n",
    "# learning_rate_init : initial value of the learning rate, optional, default 0.001, only for sgd or adam\n",
    "# power_t : descent exponent, optional, default 0.5, applies to 'invscaling',learning_rate_init/pow(t,power_t), sgd only\n",
    "# max_iter : maximum number of iterations, optional, default 200, number of iterator convergence iterations, for\n",
    "#sgd/adam, represents the number of epochs, not the number of descent steps\n",
    "# shuffle : per iteration, whether to shuffle or not, optional, default True, only for sgd or adam\n",
    "# random_state: default None; if int, random number generator seed, if RandomStates instance, random number\n",
    "#generator, if None, np.random\n",
    "# tol : tolerance, optional, default le-4, stop iterating if loss does not reach this value in two consecutive iterations\n",
    "#unless set to 'adaptive', otherwise\n",
    "# beta_1 : adam exponent decay parameter 1, optional, default 0.9\n",
    "# beta_2 : adam exponential decay parameter 2, optional, default 0.999\n",
    "# epsilon : adam numerical stability value, optional, default 1e-8\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29e46ad",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the test set is: 0.7555555555555555\n",
      "The Current value of the loss function of the training set is: 0.47502840629835674\n",
      "The weight value : [array([[ 2.29361868e-01, -1.84662371e-01, -1.07750640e-01,\n",
      "         1.88256473e-01, -2.20843874e-01, -2.04274842e-02,\n",
      "         2.44952213e-01,  3.74655225e-01, -1.22549319e-01,\n",
      "         2.63707251e-01,  2.69761436e-01,  2.86764247e-01,\n",
      "         4.05970873e-01, -6.54786763e-02,  4.57786227e-01,\n",
      "        -6.09816887e-03, -9.93848332e-02, -1.49940540e-01,\n",
      "         3.41474617e-01, -1.78409938e-01],\n",
      "       [ 2.18532255e-01, -2.41621981e-01, -1.07581323e-04,\n",
      "        -1.46304799e-01, -4.21643294e-02,  4.48342920e-01,\n",
      "         1.85997034e-01,  1.66325349e-01, -8.86936382e-04,\n",
      "         2.80366949e-01, -5.71272604e-02, -2.21243863e-01,\n",
      "        -3.27146567e-01,  3.20024257e-01,  1.28703430e-01,\n",
      "         1.85013537e-02,  2.25010083e-09,  6.18989550e-05,\n",
      "         3.69692493e-02, -2.07493180e-03],\n",
      "       [-4.90173129e-01, -1.29817190e-01,  7.57876830e-02,\n",
      "         3.64675713e-01,  1.45914994e-01, -1.53415389e-01,\n",
      "        -4.37348320e-01, -2.25111206e-01,  1.15106949e-09,\n",
      "         3.88738449e-01, -5.65858478e-01, -2.42915838e-01,\n",
      "         1.03556697e-01, -5.49973214e-01, -5.52367806e-01,\n",
      "        -5.15000464e-03, -1.56332645e-01, -5.25823087e-03,\n",
      "        -4.27069484e-01, -1.04004999e-01],\n",
      "       [ 4.51474365e-01, -2.36588571e-02, -3.87700471e-02,\n",
      "         3.83887792e-01,  1.17711839e-01, -6.37534394e-01,\n",
      "        -2.73087585e-02,  3.78761043e-01, -1.92770631e-01,\n",
      "         1.74438269e-01, -2.90127926e-01, -3.33622440e-01,\n",
      "        -5.32851884e-01, -1.50294831e-01,  9.59743007e-02,\n",
      "        -6.46165697e-02, -1.05198485e-01,  2.15855610e-01,\n",
      "         2.13844277e-01, -9.66373495e-03]]), array([[ 2.84209133e-01, -3.80739106e-01,  2.43474532e-01],\n",
      "       [-1.51305072e-03,  1.71040130e-01,  1.24687862e-01],\n",
      "       [-1.20841635e-08, -1.58069652e-01, -1.42422240e-01],\n",
      "       [-3.46991239e-01,  1.46181691e-01,  2.99609941e-01],\n",
      "       [ 1.14614608e-02,  6.96672987e-09,  1.38387669e-01],\n",
      "       [ 6.21602577e-01, -6.52254572e-01,  1.24673492e-03],\n",
      "       [ 6.75766959e-02, -5.00250469e-01, -7.56610478e-01],\n",
      "       [-2.01183297e-01,  1.35422045e-02,  1.86032192e-01],\n",
      "       [-6.17594128e-03, -3.81428469e-04, -7.62769710e-02],\n",
      "       [-1.91571800e-01, -1.38926318e-01,  1.06896121e-01],\n",
      "       [-3.54648481e-01, -2.83740410e-03,  3.57213539e-02],\n",
      "       [ 1.06209003e-01,  2.81920273e-01,  3.34605773e-01],\n",
      "       [ 3.65852007e-01, -7.34633348e-03,  1.29478313e-01],\n",
      "       [-3.18846092e-01,  3.79170189e-01,  1.57223651e-01],\n",
      "       [ 3.50102179e-01,  3.40689641e-01, -1.01648363e-01],\n",
      "       [-6.34637161e-04, -1.25060334e-01, -7.18388320e-10],\n",
      "       [ 2.36080417e-01,  2.19557633e-01, -1.15774320e-03],\n",
      "       [-2.87328934e-10,  1.34306893e-03,  4.52352190e-02],\n",
      "       [ 4.08635593e-02,  1.46119540e-01, -3.97885933e-01],\n",
      "       [-3.22320655e-09, -1.93007326e-07, -4.76944063e-07]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nada7\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(20),alpha=0.01,max_iter=300)\n",
    "# The model can be trained by calling the fit function. The general method of training by calling the model function is\n",
    "#fit()\n",
    "mlp.fit(X_train,y_train) # Here the y value needs to be reduced to a one-dimensional array\n",
    "# This is how the model is trained, and we can then call a variety of functions to get the trained parameters\n",
    "# For example, to get the accuracy rate\n",
    "print('The accuracy of the test set is:',mlp.score(X_test,y_test))\n",
    "# e.g. output the current Current value of the loss function\n",
    "print('The Current value of the loss function of the training set is:',mlp.loss_)\n",
    "# For example, output the weights of each theta\n",
    "print('The weight value :',mlp.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88aa08af",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for the training set is:\n",
      " [[16  0  0]\n",
      " [ 0  7 11]\n",
      " [ 0  0 11]]\n",
      "The classification report for the training set is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.39      0.56        18\n",
      "           2       0.50      1.00      0.67        11\n",
      "\n",
      "    accuracy                           0.76        45\n",
      "   macro avg       0.83      0.80      0.74        45\n",
      "weighted avg       0.88      0.76      0.74        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The confusion matrix and classification report is an indicator of the predicted and true values\n",
    "# The confusion matrix provides a visual indication of the number of correct and incorrect classifications, and the\n",
    "#category to which the correct samples were incorrectly classified\n",
    "matrix_test = confusion_matrix(y_test,mlp.predict(X_test))\n",
    "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
    "# There are multiple metrics in the classification report to evaluate how good the prediction is.\n",
    "# '''\n",
    "# TP: Prediction is 1 (Positive), actual is also 1 (Truth-prediction is correct)\n",
    "# TN: predicted 0 (Negative), also 0 (Truth - predicted correctly)\n",
    "# FP: predicted 1 (Positive), actually 0 (False - wrong prediction)\n",
    "# FN: Prediction is 0 (Negative), actual is 1 (False-prediction is wrong)\n",
    "# '''\n",
    "report_test = classification_report(y_test,mlp.predict(X_test))\n",
    "print(f'The classification report for the training set is: \\n {report_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
